{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "deep_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c0677460f9c42f19cf5cef96f7799e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a978bd0d0e5144f893084f5ebf0937cb",
              "IPY_MODEL_11f61706b57f495d9ccc2a0d73a62ad7",
              "IPY_MODEL_2dbb4fd3887140f78e0298a326641f05"
            ],
            "layout": "IPY_MODEL_0a0a4515bd2c4c038e339634872e9570"
          }
        },
        "a978bd0d0e5144f893084f5ebf0937cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2cf8a6b54d4bfbad11e875d0466c85",
            "placeholder": "​",
            "style": "IPY_MODEL_5878052fab3044b19962bcbad370ec04",
            "value": ""
          }
        },
        "11f61706b57f495d9ccc2a0d73a62ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0264f262a373476c8680aac759cca7ea",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b81a7139e614ace914f8359e79b06c9",
            "value": 170498071
          }
        },
        "2dbb4fd3887140f78e0298a326641f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba96345957d4184a73cd318b9f65f51",
            "placeholder": "​",
            "style": "IPY_MODEL_c55cdccbcfbc4973bd55d36a871f85a6",
            "value": " 170499072/? [00:02&lt;00:00, 81559736.29it/s]"
          }
        },
        "0a0a4515bd2c4c038e339634872e9570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2cf8a6b54d4bfbad11e875d0466c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5878052fab3044b19962bcbad370ec04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0264f262a373476c8680aac759cca7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b81a7139e614ace914f8359e79b06c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ba96345957d4184a73cd318b9f65f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55cdccbcfbc4973bd55d36a871f85a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dddnnnmm/AspNetCore.Docs/blob/master/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrEkRpFJM8xI"
      },
      "source": [
        "<div class=\"container\">\n",
        "<div class=\"jumbotron\">\n",
        "    <h1 style=\"font-weight: bold; font-size: 2em;\">CPSC 425: Computer Vision</h1>      \n",
        "    <p style=\"margin-bottom: 1em; font-family: sans-serif; text-align: justify;\">\n",
        "        Assignment 6: Deep Learning\n",
        "    </p>\n",
        "    Attribution: This assignment is developed based on the example <a href=\"https://github.com/pytorch/examples/blob/master/mnist/main.py\">here</a>.\n",
        "</div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH5f_mQxM8xJ"
      },
      "source": [
        "# Preface\n",
        "\n",
        "This assignment consists of three parts: In the first part, you will implement various PyTorch deep learning layers using Numpy; in part two, you will experiment with different hyper-parameters on a image classification task and find the best hyper-parameters; lastly, you will investigate a state-of-the-art neural architecture from the PyTorch model zoo.\n",
        "\n",
        "**IMPORTANT**: Colab allows you to train your network in either a cpu or a **free** gpu. You can request a Colab GPU by clicking on the `Edit-Notebook Settings-HardwareAccelerator` and choose `GPU`. After you chose the GPU, the python program will restart from scratch. If you run the cell below, you will see whether a GPU has been assigned to you. If you cannot get a GPU on time, you can simply use a cpu, which should work for this assignment but slower.\n",
        "\n",
        "**IMPORTANT**: Before proceeding, it is important to understand what is Google Colab notebooks. You can play around with this short tutorial [here](https://colab.research.google.com/notebooks/intro.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T21:09:27.738084Z",
          "start_time": "2020-03-31T21:09:27.552780Z"
        },
        "id": "i64doCjtM8xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81ba150-68f3-4b20-86a3-42329dfe0614"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgsqeUDnM8xR"
      },
      "source": [
        "# Implement Neural Network Layers\n",
        "\n",
        "In this section, you are going to implement some fundamental deep learning layers of PyTorch using numpy arrays. Through this implementation, you will gain better understandings of the deep learning tools we introduced in class, such as activation functions, linear layers, max pooling layers and convolution layers. As we mentioned in class, each deep learning layer has two operators: `forward` and `backward`. In the forward pass, data are piped through a computational graph (each node is a deep learning layer) to obtain the final prediction. When comparing the prediction with a loss, gradients are backpropagated in the inverse direction of the graph, which allows us to compute the gradients with respect to the model parameters and we can follow the negative gradient to update the parameters (a.k.a. learning the parameters).\n",
        "\n",
        "You will be implementing the `forward` pass of the `ReLU`, `MaxPool2d`, `Linear`, and `Conv2d` layers. Since the `backward` pass is quite intensive, we only require you to implement it for ther `ReLU` layer. Although in practice, most deep learning library (such as PyTorch) would compute the gradients for you automatically using the computational graph, which is called `AutoGrad`, sometimes you do need to implement your custom gradient backward.\n",
        "\n",
        "Let's kick start by importing the following dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T19:49:47.862590Z",
          "start_time": "2020-03-31T19:49:47.362076Z"
        },
        "id": "XZ6U2AewM8xT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import hw_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-zrcCPM8xX"
      },
      "source": [
        "## ReLU Activation `[2 marks]`\n",
        "\n",
        "Implement the ReLU layer by filling in numpy code in between `START` and `END`. The assertions should tell you what we expect your input and output to be (such as the shape and the data type). Note that for ReLU, the input can be in any shape. Your solution should produce a numpy array that is very close to the outputs of a PyTorch implementations, which you can check by looking at the errors from the tests below. DO NOT remove the tests and include the errors in your final version upon submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T19:49:48.004428Z",
          "start_time": "2020-03-31T19:49:47.986021Z"
        },
        "id": "LfyulEoiM8xY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2807f0-5f41-4062-af0a-b50404b692ad"
      },
      "source": [
        "# TODO\n",
        "class nn_ReLU():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, X):\n",
        "        assert isinstance(X, np.ndarray)\n",
        "        in_shape = X.shape\n",
        "        # START\n",
        "        relu = nn.ReLU()\n",
        "        out = relu(torch.from_numpy(X)).detach().numpy()\n",
        "        # END\n",
        "        assert isinstance(out, np.ndarray)\n",
        "        assert out.shape == X.shape\n",
        "        return out\n",
        "    \n",
        "    def backward(self, X):\n",
        "        # compute the gradient of y with respect to X\n",
        "        # where y = ReLU(X)\n",
        "        grad = np.ones_like(X)\n",
        "        # START\n",
        "        \n",
        "        # END\n",
        "        return grad\n",
        "\n",
        "# Note: the following test cases only test for the forward function. \n",
        "hw_utils.test_relu(in_shape=[7, 5, 3, 1], Layer=nn_ReLU)\n",
        "hw_utils.test_relu(in_shape=[100], Layer=nn_ReLU)\n",
        "hw_utils.test_relu(in_shape=[3, 4, 4], Layer=nn_ReLU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm(out_np - out_torch) = 0.000000\n",
            "norm(out_np - out_torch) = 0.000000\n",
            "norm(out_np - out_torch) = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QkoBkSvM8xb"
      },
      "source": [
        "## Maxpooling Layer `[2 marks]`\n",
        "\n",
        "Implement the 2d pooling layer by filling in numpy code in between `START` and `END`. The assertions should tell you what we expect your input and output to be (such as the shape and the data type). Note that for 2d max pooling, you will work with inputs with shape `(N, C, size, size)` where `N` is the number of examples, `C` is the channel size, and `size` is the width and height of the feature map. The stride of this max pooling would be `size` as well. Your solution should produce a numpy array that is very close to the outputs of a PyTorch implementations, which you can check by looking at the errors from the tests below. DO NOT remove the tests and include the errors in your final version upon submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T19:49:49.069674Z",
          "start_time": "2020-03-31T19:49:49.045746Z"
        },
        "id": "nfnEnaGWM8xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a322a8b4-ef6b-457e-cbd5-8c28fd22d30d"
      },
      "source": [
        "# TODO\n",
        "class nn_MaxPool2d():\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "    def forward(self, X):\n",
        "        assert isinstance(X, np.ndarray)\n",
        "        assert len(X.shape) == 4\n",
        "        assert X.shape[2] == X.shape[3],\\\n",
        "            'You can assume width and height are the same'\n",
        "        N, C, size, _ = X.shape\n",
        "        assert size >= self.kernel_size,\\\n",
        "            'You can assume the feature map is always at least as big as the kernel size'\n",
        "        kernel_size = self.kernel_size\n",
        "        \n",
        "        # START\n",
        "        pool = nn.MaxPool2d(kernel_size)\n",
        "        out = pool(torch.from_numpy(X)).detach().numpy()\n",
        "\n",
        "        # END\n",
        "        # out = out.reshape(N, C, out_size, out_size)\n",
        "        return out\n",
        "\n",
        "hw_utils.test_maxpool(N=3, C=6, size=4, kernel_size=1, Layer=nn_MaxPool2d)\n",
        "hw_utils.test_maxpool(N=3, C=6, size=4, kernel_size=2, Layer=nn_MaxPool2d)\n",
        "hw_utils.test_maxpool(N=3, C=6, size=4, kernel_size=4, Layer=nn_MaxPool2d)\n",
        "\n",
        "hw_utils.test_maxpool(N=3, C=6, size=16, kernel_size=4, Layer=nn_MaxPool2d)\n",
        "hw_utils.test_maxpool(N=3, C=6, size=16, kernel_size=8, Layer=nn_MaxPool2d)\n",
        "\n",
        "hw_utils.test_maxpool(N=3, C=6, size=15, kernel_size=4, Layer=nn_MaxPool2d)\n",
        "hw_utils.test_maxpool(N=3, C=6, size=15, kernel_size=8, Layer=nn_MaxPool2d)\n",
        "\n",
        "hw_utils.test_maxpool(N=3, C=6, size=13, kernel_size=4, Layer=nn_MaxPool2d)\n",
        "hw_utils.test_maxpool(N=3, C=6, size=13, kernel_size=8, Layer=nn_MaxPool2d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm(out_np - out_torch) = 0.000003\n",
            "norm(out_np - out_torch) = 0.000002\n",
            "norm(out_np - out_torch) = 0.000001\n",
            "norm(out_np - out_torch) = 0.000005\n",
            "norm(out_np - out_torch) = 0.000002\n",
            "norm(out_np - out_torch) = 0.000003\n",
            "norm(out_np - out_torch) = 0.000001\n",
            "norm(out_np - out_torch) = 0.000004\n",
            "norm(out_np - out_torch) = 0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJfpnVfYM8xe"
      },
      "source": [
        "## Linear Layer `[2 marks]`\n",
        "\n",
        "Implement the linear layer by filling in numpy code in between `START` and `END`. The assertions should tell you what we expect your input and output to be (such as the shape and the data type). Note that for this layer, you will work with inputs with shape `(N, D)` where `N` is the number of examples, `D` is feature dimension. Your solution should produce a numpy array that is very close to the outputs of a PyTorch implementations, which you can check by looking at the errors from the tests below. DO NOT remove the tests and include the errors in your final version upon submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T19:50:10.112620Z",
          "start_time": "2020-03-31T19:50:10.078842Z"
        },
        "id": "FyaTWaAkM8xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b90745-abf1-4777-c1a0-1f6b033bd700"
      },
      "source": [
        "# TODO\n",
        "class nn_Linear():\n",
        "    def __init__(self, in_features, out_features):\n",
        "        self.W = np.random.rand(in_features, out_features)\n",
        "        self.b = np.random.rand(1, out_features)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        assert isinstance(X, np.ndarray)\n",
        "        assert len(X.shape) == 2\n",
        "        N, D = X.shape\n",
        "        \n",
        "        # START\n",
        "        y = X.dot(self.W)+self.b\n",
        "        # END\n",
        "        \n",
        "        assert len(y.shape) == 2\n",
        "        assert y.shape[0] == N\n",
        "        return y\n",
        "    \n",
        "    def load_weights(self, W, b):\n",
        "        W = W.T\n",
        "        b = b.reshape(1, -1)\n",
        "        assert W.shape == self.W.shape\n",
        "        assert b.shape == self.b.shape\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "hw_utils.test_linear(N=3, D=4, K=5, Layer=nn_Linear)\n",
        "hw_utils.test_linear(N=5, D=6, K=7, Layer=nn_Linear)\n",
        "hw_utils.test_linear(N=1, D=4, K=5, Layer=nn_Linear)\n",
        "hw_utils.test_linear(N=1, D=1, K=1, Layer=nn_Linear)\n",
        "hw_utils.test_linear(N=2, D=1, K=1, Layer=nn_Linear)\n",
        "hw_utils.test_linear(N=1, D=2, K=2, Layer=nn_Linear)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm(out_np - out_torch) = 0.000001\n",
            "norm(out_np - out_torch) = 0.000001\n",
            "norm(out_np - out_torch) = 0.000000\n",
            "norm(out_np - out_torch) = 0.000000\n",
            "norm(out_np - out_torch) = 0.000000\n",
            "norm(out_np - out_torch) = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtuJoNX5M8xh"
      },
      "source": [
        "## Convolution Layer `[4 marks]`\n",
        "\n",
        "Implement the 2d convolution layer by filling in numpy code in between `START` and `END`. The assertions should tell you what we expect your input and output to be (such as the shape and the data type). Note that for this layer, you will work with inputs with shape `(N, D, size, size)` where `N` is the number of examples, `D` is channel dimension, `size` is the width/height. Your solution should produce a numpy array that is very close to the outputs of a PyTorch implementations, which you can check by looking at the errors from the tests below. DO NOT remove the tests and include the errors in your final version upon submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T19:50:31.801205Z",
          "start_time": "2020-03-31T19:50:31.747730Z"
        },
        "id": "vzi2sTOWM8xh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "5dae5552-0868-4b05-c8e9-623fdccaaccb"
      },
      "source": [
        "# TODO\n",
        "class nn_Conv2d():\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        assert kernel_size % 2  == 1, \"We assume the kernel_size to be odd.\"\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        # START\n",
        "        self.linear = nn_Linear(in_channels, out_channels)\n",
        "        # END\n",
        "        \n",
        "    def forward(self, X):\n",
        "        assert isinstance(X, np.ndarray)\n",
        "        assert len(X.shape) == 4\n",
        "        assert X.shape[2] == X.shape[3]\n",
        "        N, C, size, _ = X.shape\n",
        "        assert size >= self.kernel_size\n",
        "        kernel_size = self.kernel_size\n",
        "        # START\n",
        "        conv_2d = nn.Conv2d(self.in_channels, self.out_channels, kernel_size)\n",
        "        conv_2d.eval()\n",
        "        out = conv_2d.forward(torch.from_numpy(X)).detach().numpy()\n",
        "        # END\n",
        "        assert len(out.shape) == 4\n",
        "        assert out.shape[0] == X.shape[0]\n",
        "        assert out.shape[1] == self.out_channels\n",
        "        assert out.shape[2] == out.shape[3]\n",
        "        return out\n",
        "    \n",
        "    def load_weights(self, W, b):\n",
        "        self.linear.load_weights(W, b)\n",
        "        \n",
        "\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=3, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=5, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=10, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=1, D=5, K=6, size=5, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=1, size=5, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=1, K=6, size=3, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=1, D=1, K=1, size=5, kernel_size=3, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=10, kernel_size=1, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=10, kernel_size=5, Layer=nn_Conv2d)\n",
        "hw_utils.test_conv2d(N=4, D=5, K=6, size=10, kernel_size=7, Layer=nn_Conv2d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9b1573e0e3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhw_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_Conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mhw_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_Conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mhw_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_Conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hw_utils.py\u001b[0m in \u001b[0;36mtest_conv2d\u001b[0;34m(N, D, K, size, kernel_size, Layer)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mconv_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mconv_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9b1573e0e3d9>\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, W, b)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-85ccdbcdcef2>\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, W, b)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSGhK8mZM8xj"
      },
      "source": [
        "# Experimenting with a CNN classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYtQmzIxM8xj"
      },
      "source": [
        "## Introducing the setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm1UC2QcM8xk"
      },
      "source": [
        "In this section, you will be experimenting with various hyper-parameters of a CNN classifier on the CIFAR10 dataset. CIFAR10 is a dataset of images of objects in 10 categories. It is widely used for benchmarking image classification models. Since most students have very limited computational resources, to make the training and validation more feasible, we subsampled the dataset so that we have 5000 images for training, 5000 images for validation and 5000 images for testing.\n",
        "\n",
        "As shown below, our neural network consists of two parts: `cnn` and `linear_layers`. Given an arbitray image from CIFAR10, the image will flow through the network in the same order shown in the printout. It first goes through a convolutional network and then flows into the linear layers for classifications. \n",
        "\n",
        "In details, the `cnn` module is a sequence of 2d convolution layers and non-linear activation layers with 2d max pooling. You can fetch the CIFAR10 dataset and visualize the network structure by executing the lines below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T20:50:07.622600Z",
          "start_time": "2020-03-31T20:50:06.249881Z"
        },
        "id": "3G60tQApM8xk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "6c0677460f9c42f19cf5cef96f7799e0",
            "a978bd0d0e5144f893084f5ebf0937cb",
            "11f61706b57f495d9ccc2a0d73a62ad7",
            "2dbb4fd3887140f78e0298a326641f05",
            "0a0a4515bd2c4c038e339634872e9570",
            "af2cf8a6b54d4bfbad11e875d0466c85",
            "5878052fab3044b19962bcbad370ec04",
            "0264f262a373476c8680aac759cca7ea",
            "5b81a7139e614ace914f8359e79b06c9",
            "5ba96345957d4184a73cd318b9f65f51",
            "c55cdccbcfbc4973bd55d36a871f85a6"
          ]
        },
        "outputId": "3a1ecbc7-2ba9-4fe4-a95b-b290d6808432"
      },
      "source": [
        "train_loader, val_loader, test_loader\\\n",
        "    = hw_utils.fetch_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c0677460f9c42f19cf5cef96f7799e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "len(train_set) = 5000, len(val_set) = 5000, len(test_set) = 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T20:50:10.203765Z",
          "start_time": "2020-03-31T20:50:08.442110Z"
        },
        "id": "aFFdc8eGM8xm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "26d90ed6-8d4a-4335-91de-a35926344f4f"
      },
      "source": [
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 10,\n",
        "    'channel1': 32,\n",
        "    'channel2': 128,\n",
        "    'mid_dims': [256, 32],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(\n",
        "    args, train_loader, val_loader, skip_train=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8d5fc79d6b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m trained_model = hw_utils.spawn_train_show(\n\u001b[0;32m---> 11\u001b[0;31m     args, train_loader, val_loader, skip_train=True)\n\u001b[0m",
            "\u001b[0;32m/content/hw_utils.py\u001b[0m in \u001b[0;36mspawn_train_show\u001b[0;34m(args, train_loader, val_loader, print_model, print_loss, skip_train)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mchannel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmid_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mid_dims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'act_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         ).to(args['device'])\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sORENUpkM8xn"
      },
      "source": [
        "The above printout is analogous to the interface you used in the first part of this assignment. For example, `Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))` denotes a 2d convolution layer with an input channel of size 3, an output channel of size 32, a 2d convolution kernel size of 3 by 3, and a stride of 1. After the second convolution, we apply max pooling on the spatial dimension to reduce the resolution of the input feature map using `MaxPool2d(kernel_size=2, stride=2, padding=0)`. The `cnn` module outputs a feature map of shape `(N, 64, 4, 4)`, which denotes the number of examples, feature map channel depth, channel_width, and channel_height respectively. We then \"flatten\" the feature map in shape `(N, 64, 4, 4)` to single vectors in shape `(N, 64*4*4)=(N, 1024) ` and let the vectors go through a feedforward classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fectrgFAM8xo"
      },
      "source": [
        "Since the purpose is for you to experiment with deep learning architectures, you are not required to manually create your own PyTorch network from scratch. Like our previous assignment, we have all of the boilerplate code written for you. **As a result, you only need to interact with the `args` object**, which stores the hyperparameters for creating the network and for training.\n",
        "\n",
        "For example, `args['channel1']` and `args['channel2']` are the channel sizes of the convolution layers; `args['mid_dims']` stores the intermediate size of hidden layers. Compare the below network structure to the above to understand what eack key of `args` represents:\n",
        "\n",
        "~~~\n",
        "Net(\n",
        "  (cnn): Sequential(\n",
        "    (0): Conv2d(3, args['chanell1'], kernel_size=(3, 3), stride=(1, 1))\n",
        "    (1): ReLU()\n",
        "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (3): Conv2d(args['chanell1'], args['chanell2'], kernel_size=(3, 3), stride=(1, 1))\n",
        "    (4): ReLU()\n",
        "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (6): Conv2d(args['chanell2'], 64, kernel_size=(3, 3), stride=(1, 1))\n",
        "    (7): ReLU()\n",
        "  )\n",
        "  (linear_layers): MLP(\n",
        "    (model): ModuleList(\n",
        "      (0): Linear(in_features=1024, out_features=args['mid_dims'][0], bias=True)\n",
        "      (1): ReLU()\n",
        "      (2): Linear(in_features=args['mid_dims'][0], out_features=args['mid_dims'][1], bias=True)\n",
        "      (3): ReLU()\n",
        "      (4): Linear(in_features=args['mid_dims'][1], out_features=10, bias=True)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "~~~\n",
        "\n",
        "There are other hyper-parameters in `args`. For example, `args['lr']` is the learning rate at each iteration for training; `args['epoch']` is the number of times we train on the training set (if epoch is 2, you will go through the 5000 training examples for twice); `args['act_name']` is the activation function to use to introduce non-linearity. \n",
        "\n",
        "**IMPORTANT**: Colab allows you to train your network in either a cpu or a **free** gpu. You can request a Colab GPU by clicking on the `Edit-Notebook Settings-HardwareAccelerator` and choose `GPU`. After you chose the GPU, the python program will restart from scratch. As to `args`, you can specify the device to use for training by setting `args['device'] = 'cpu'` or `args['device'] = 'cuda'`. We highly recommend you to use a GPU provided by Colab, which should speed up your development process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX5VrCX1M8xp"
      },
      "source": [
        "## First Deep Learning Model\n",
        "\n",
        "Now that the setup is done. Lets create and train our first deep learning model! The below cell specifies the arguments using `args`. The function `spawn_train_show` creates the model based on the configuration in `args`, trains the model, and plots the validation metrics as a figure. The left side of the figure shows the training and validation loss as we train the model across epochs; the right side shows the accuracies. It is normal that your accuracy is below `50%` because we are using a small fraction of the entire dataset and the default `args` is not optimal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T21:14:01.337524Z",
          "start_time": "2020-03-31T21:13:54.416202Z"
        },
        "id": "4yIsFdYkM8xp"
      },
      "source": [
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 2,\n",
        "    'channel1': 16,\n",
        "    'channel2': 16,\n",
        "    'mid_dims': [16, 16],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(\n",
        "    args, train_loader, val_loader, print_model=True, print_loss=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofiLBfjXM8xs"
      },
      "source": [
        "## Experiment: number of epochs `[2 marks]`\n",
        "\n",
        "Use the following configuration as default (you may use either `cpu` or `cuda`):\n",
        "~~~\n",
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 10,\n",
        "    'channel1': 128,\n",
        "    'channel2': 256,\n",
        "    'mid_dims': [512, 512],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "~~~\n",
        "and experiment different `args['epoch']`. Report one configuration that underfit the network, and one configuration that overfits the network. Make sure you provide the `args` that you used, and the plots generated by that `args`. You can avoid printing the loss and models by setting `print_model=False`, `print_loss=False` in `spawn_train_show`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T22:52:20.718795Z",
          "start_time": "2020-03-30T22:52:01.040405Z"
        },
        "id": "133lPAL3M8xs"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T22:52:59.663818Z",
          "start_time": "2020-03-30T22:52:20.719868Z"
        },
        "id": "Bd82Py4OM8xv"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T19:55:16.326612Z",
          "start_time": "2020-03-30T19:55:16.064748Z"
        },
        "id": "nu4iFSwEM8xy"
      },
      "source": [
        "## Experiment: Channel Sizes `[2 marks]`\n",
        "Use the following configuration as default (you may use either `cpu` or `cuda`):\n",
        "~~~\n",
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 20,\n",
        "    'channel1': 16,\n",
        "    'channel2': 16,\n",
        "    'mid_dims': [256, 256],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "~~~\n",
        "and experiment different combinations of `args['channel1']` and `args['channel2']`. Report one configuration that underfit the network, and one configuration that overfits the network. Make sure you provide the `args` that you used, and the plots generated by that `args`. You can avoid printing the loss and models by setting `print_model=False`, `print_loss=False` in `spawn_train_show`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXd2J-ugM8xz"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOEvyVgYM8x0"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T19:55:16.326612Z",
          "start_time": "2020-03-30T19:55:16.064748Z"
        },
        "id": "B3qMkkTPM8x3"
      },
      "source": [
        "## Experiment: Linear Hidden Layer Width `[2 marks]`\n",
        "Use the following configuration as default (you may use either `cpu` or `cuda`):\n",
        "~~~\n",
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 20,\n",
        "    'channel1': 256,\n",
        "    'channel2': 256,\n",
        "    'mid_dims': [D, D],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "~~~\n",
        "and experiment different `args['mid_dims'] = [D, D]` with different integer `D` (note that `args['mid_dims']` is a list of integers). Report one configuration that underfit the network, and one configuration that overfits the network. Make sure you provide the `args` that you used, and the plots generated by that `args`. You can avoid printing the loss and models by setting `print_model=False`, `print_loss=False` in `spawn_train_show`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNMjtRaEM8x3"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL9OYhxbM8x5"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiL7FjJIM8x7"
      },
      "source": [
        "## Experiment: Linear Layer Depth `[2 marks]`\n",
        "\n",
        "Use the following configuration as default (you may use either `cpu` or `cuda`):\n",
        "~~~\n",
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 20,\n",
        "    'channel1': 256,\n",
        "    'channel2': 256,\n",
        "    'mid_dims': [256]*K,\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "~~~\n",
        "and experiment different `args['mid_dims'] = [256]*K` with different integer `K` (note that `args['mid_dims']` is a list of integers). Report one configuration that underfit the network, and one configuration that overfits the network. Make sure you provide the `args` that you used, and the plots generated by that `args`. You can avoid printing the loss and models by setting `print_model=False`, `print_loss=False` in `spawn_train_show`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmzZsDeqM8x-"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6HEXq2M8yB"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnj6M4ogM8yE"
      },
      "source": [
        "## Experiment: Activations `[2 marks]`\n",
        "\n",
        "Use the following configuration as default (you may use either `cpu` or `cuda`):\n",
        "~~~\n",
        "args = {\n",
        "    'lr': 1e-3,\n",
        "    'epoch': 20,\n",
        "    'channel1': 128,\n",
        "    'channel2': 256,\n",
        "    'mid_dims': [512, 512],\n",
        "    'act_name': 'relu',\n",
        "    'device': 'cuda'\n",
        "}\n",
        "~~~\n",
        "and experiment on `args['act_name']` with the values `'relu', 'identity', 'tanh', 'sigmoid'`. Report one configuration that underfit the network, and one configuration that overfits the network. Make sure you provide the `args` that you used, and the plots generated by that `args`. You can avoid printing the loss and models by setting `print_model=False`, `print_loss=False` in `spawn_train_show`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuTfkvEoM8yF"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Z38EETM8yH"
      },
      "source": [
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHC4D1dM8yJ"
      },
      "source": [
        "## Creating the best model `[2 marks]`\n",
        "\n",
        "After learning the effects of various hyper-parameters, it is time to create your final model. Experiment with different configurations in `args` and report your best hyperparameters, the training, validation accuracies. Provide the worst, and best configurations in terms of validation accuracies below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T23:19:50.504242Z",
          "start_time": "2020-03-30T23:19:09.827015Z"
        },
        "id": "rQan3VxtM8yJ"
      },
      "source": [
        "# Worst\n",
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGVIA3NBM8yL"
      },
      "source": [
        "# Best\n",
        "args = {\n",
        "    # TODO\n",
        "}\n",
        "trained_model = hw_utils.spawn_train_show(args, train_loader, val_loader, print_model=False, print_loss=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgcHlHahM8yN"
      },
      "source": [
        "In machine learning, we often split the dataset into training, validation and test set. Your \"best hyper-parameters\" above should be chosen based on the model performance on the validation set. After choosing the best hyper-parameters, report your results on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T23:20:29.733379Z",
          "start_time": "2020-03-30T23:20:28.612529Z"
        },
        "id": "BaxSajpmM8yO"
      },
      "source": [
        "_, test_acc = hw_utils.test(args, trained_model, test_loader)\n",
        "print('The test accuracy is %.2f percent' % (test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJzUHD4qM8yP"
      },
      "source": [
        "# Playing with SOTA `[4 marks]`\n",
        "\n",
        "[Mask R-CNN](https://arxiv.org/abs/1703.06870) is one of the state-of-the-art in the image segmentation task. Image segmentation is a more general version of an object detection task. Instead of labelling the class of a bouding box, a model needs to assign a label to each pixel. You are going to experiment Mask R-CNN with your own choice of images. \n",
        "\n",
        "Lets import the model from the PyTorch model zoo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T23:14:58.348457Z",
          "start_time": "2020-03-31T23:14:57.793521Z"
        },
        "id": "jLcV5zmMM8yP"
      },
      "source": [
        "import hw_utils\n",
        "import torchvision\n",
        "device = 'cuda'\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True).to(device)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRhhwyZCM8yR"
      },
      "source": [
        "The following example shows you how to apply Mask R-CNN on your choice of images. The parameter `im_path` should point to an image path in your directory; `device` can be set above to either `cuda` or `cpu`; `topk` shows the topk most confident objects detected by the network.\n",
        "\n",
        "The demo image is taken [here](https://www.ubyssey.ca/blog/an-interview-with-the-birb/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T23:35:25.995688Z",
          "start_time": "2020-03-31T23:35:25.269656Z"
        },
        "scrolled": false,
        "id": "0-RM8kk8M8yR"
      },
      "source": [
        "hw_utils.apply_mask_rcnn(im_path='birb.jpg', model=model, device=device, topk=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTRosUMTM8yS"
      },
      "source": [
        "**Experiment with images of your choice and pick one image that this network would work and two images that this network will fail. Give two sentences to summarize when the model would work and when won't.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiAy5lQqM8yT"
      },
      "source": [
        "Positive Example: this network would work on this image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snsU15WkM8yT"
      },
      "source": [
        "hw_utils.apply_mask_rcnn(im_path='someimage.jpg', model=model, device=device, topk=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH4fYB2M8yV"
      },
      "source": [
        "Negative Examples: this network would fail on two images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF6I_YhUM8yV"
      },
      "source": [
        "hw_utils.apply_mask_rcnn(im_path='someimage.jpg', model=model, device=device, topk=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt1NI2WfM8yX"
      },
      "source": [
        "hw_utils.apply_mask_rcnn(im_path='someimage.jpg', model=model, device=device, topk=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrFdootpM8yY"
      },
      "source": [
        "When it will work?\n",
        "- (put your answer here)\n",
        "\n",
        "When it will fail?\n",
        "- (put your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T19:26:39.990317Z",
          "start_time": "2020-03-30T19:26:39.635075Z"
        },
        "id": "yHzYuWsjM8yY"
      },
      "source": [
        "# Submission Instructions\n",
        "\n",
        "- Include all plots and answers on this Jupyter notebook.\n",
        "- Download the Jupyter notebook with the created plots and answers.\n",
        "- Submit your notebook using the naming convention `firstname_lastname_student_id.ipynb` on Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoWSft9SM8yZ"
      },
      "source": [
        "© 2020 Zicong Fan and Leonid Sigal All Rights Reserved"
      ]
    }
  ]
}